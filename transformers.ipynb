{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encoder = lambda s: [stoi[c] for c in s]\n",
    "decoder = lambda l: ''.join([itos[i] for i in l])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43, 2]\n",
      "hii there!\n"
     ]
    }
   ],
   "source": [
    "print(encoder('hii there!'))\n",
    "print(decoder(encoder('hii there!')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(text))\n",
    "data_tensor = torch.tensor(encoder(text), dtype=torch.long)\n",
    "train_data = data_tensor[:n]\n",
    "val_data = data_tensor[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]), the target is: 47\n",
      "when input is tensor([18, 47]), the target is: 56\n",
      "when input is tensor([18, 47, 56]), the target is: 57\n",
      "when input is tensor([18, 47, 56, 57]), the target is: 58\n",
      "when input is tensor([18, 47, 56, 57, 58]), the target is: 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]), the target is: 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is: 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is: 58\n"
     ]
    }
   ],
   "source": [
    "x_demo = train_data[:block_size]\n",
    "y_demo = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x_demo[:t+1]\n",
    "    target = y_demo[t]\n",
    "    print(f\"when input is {context}, the target is: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "\n",
      "\n",
      "for the input [24], the target is 43\n",
      "for the input [24, 43], the target is 58\n",
      "for the input [24, 43, 58], the target is 5\n",
      "for the input [24, 43, 58, 5], the target is 57\n",
      "for the input [24, 43, 58, 5, 57], the target is 1\n",
      "for the input [24, 43, 58, 5, 57, 1], the target is 46\n",
      "for the input [24, 43, 58, 5, 57, 1, 46], the target is 43\n",
      "for the input [24, 43, 58, 5, 57, 1, 46, 43], the target is 39\n",
      "for the input [44], the target is 53\n",
      "for the input [44, 53], the target is 56\n",
      "for the input [44, 53, 56], the target is 1\n",
      "for the input [44, 53, 56, 1], the target is 58\n",
      "for the input [44, 53, 56, 1, 58], the target is 46\n",
      "for the input [44, 53, 56, 1, 58, 46], the target is 39\n",
      "for the input [44, 53, 56, 1, 58, 46, 39], the target is 58\n",
      "for the input [44, 53, 56, 1, 58, 46, 39, 58], the target is 1\n",
      "for the input [52], the target is 58\n",
      "for the input [52, 58], the target is 1\n",
      "for the input [52, 58, 1], the target is 58\n",
      "for the input [52, 58, 1, 58], the target is 46\n",
      "for the input [52, 58, 1, 58, 46], the target is 39\n",
      "for the input [52, 58, 1, 58, 46, 39], the target is 58\n",
      "for the input [52, 58, 1, 58, 46, 39, 58], the target is 1\n",
      "for the input [52, 58, 1, 58, 46, 39, 58, 1], the target is 46\n",
      "for the input [25], the target is 17\n",
      "for the input [25, 17], the target is 27\n",
      "for the input [25, 17, 27], the target is 10\n",
      "for the input [25, 17, 27, 10], the target is 0\n",
      "for the input [25, 17, 27, 10, 0], the target is 21\n",
      "for the input [25, 17, 27, 10, 0, 21], the target is 1\n",
      "for the input [25, 17, 27, 10, 0, 21, 1], the target is 54\n",
      "for the input [25, 17, 27, 10, 0, 21, 1, 54], the target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    xb = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    yb = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return xb, yb\n",
    "\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "print(\"\\n\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        print(f\"for the input {xb[b, :t+1].tolist()}, the target is {yb[b, t]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # somehow each token reads the logits for the next character from the lookup table \n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # both idx and target are of size (B, T) tensors\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # channel gotta be the last\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # cross entropy expects the dims to be (B, C, <t1, t2 ...)\n",
    "        \n",
    "        return logits, loss\n",
    "            \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            #extract the last time dim which is the prediction for the next token, dim of (B, C)\n",
    "            logits = logits[:, -1, :] # realize that the else block won't be triggered in the forward method since target is none, o.w. the logits would be (B*T, C) which this line wouldn't work\n",
    "            # assign the highest prob in the channel dim to the most likely dim to next char\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # give the probs as weight to multinomial distr to sample 1, so the idx in C dim with highest prob by softmax is the most likely to be sampled by multinom\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # In this case, dim=-1 should evaluate to dim=1\n",
    "            idx = torch.concat((idx, idx_next), dim=-1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
     ]
    }
   ],
   "source": [
    "print(decoder(m.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5727508068084717\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iyoteng h hasbe pave pirance\n",
      "Rie hicomyonthar's\n",
      "Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n",
      "KIN d pe wither vouprrouthercc.\n",
      "hathe; d!\n",
      "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
      "h hay.JUCle n prids, r loncave w hollular s O:\n",
      "HIs; ht \n"
     ]
    }
   ],
   "source": [
    "print(decoder(m.generate(torch.zeros((1, 1), dtype=torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t, C)\n",
    "        x_bow[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "\n",
      "b=\n",
      "tensor([[8., 6.],\n",
      "        [5., 2.],\n",
      "        [4., 4.]])\n",
      "\n",
      "\n",
      "c=\n",
      "tensor([[17., 12.],\n",
      "        [17., 12.],\n",
      "        [17., 12.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(1337)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"\\n\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"\\n\")\n",
    "print(\"c=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "\n",
      "b=\n",
      "tensor([[7., 4.],\n",
      "        [5., 0.],\n",
      "        [5., 3.]])\n",
      "\n",
      "\n",
      "c=\n",
      "tensor([[ 7.,  4.],\n",
      "        [12.,  4.],\n",
      "        [17.,  7.]])\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"\\n\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"\\n\")\n",
    "print(\"c=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "\n",
      "\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "thesum = torch.sum(a, -1)\n",
    "print(thesum)\n",
    "print(\"\\n\")\n",
    "thesum = torch.sum(a, -1, keepdim=True)\n",
    "print(thesum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "\n",
      "\n",
      "b=\n",
      "tensor([[8., 9.],\n",
      "        [2., 7.],\n",
      "        [3., 9.]])\n",
      "\n",
      "\n",
      "c=\n",
      "tensor([[8.0000, 9.0000],\n",
      "        [5.0000, 8.0000],\n",
      "        [4.3333, 8.3333]])\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(1337)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, -1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"\\n\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"\\n\")\n",
    "print(\"c=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v2\n",
    "## to apply the concept to our case\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (T, T) @ (B, T, C) --> torch broadcasts it to (B, T, T) @ (B, T, C) ---> (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(x_bow, xbow2) # checking whether this two are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#v3\n",
    "#ultimately softmaxing will be the go to way since the wei is like an affinity, giving how much each token occurred in the past are relevant for the token at hand currently\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(x_bow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v4 self-attention\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 # batch_size, time_steps, channel_dim\n",
    "x = torch.randn(B, T, C) # the input x, initialized as a random normal tensor of b, t, c\n",
    "\n",
    "# a single head of self attention(implying key, query and value are all obtained from the same source, x. In cross attention, key and value are obtained from an encoder, then we condition to this external information.)\n",
    "head_size = 16 # dimensionality of the head output\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x)   # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "\n",
    "# wei gives the attention values in a data dependent manner, as oppose to assigning equal influence from each token as we did before\n",
    "wei = q @ k.transpose(-2, -1) # (B, T, head_size) @ (B, head_size, T) pay attention that the dimension B is completely independent and we carry out the dot product independent of dim B\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T)) # the masking matrix, so that information won't leak from the future tokens\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\")) # for softmax to work properly, since values will be both negative and positive\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v # in the attention head, the x is kinda the private thing, and we funnel its information via value, and we operate upon it.\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layernorm, pretty similar to batch norm but instead of normalizing across dim0, we norm across dim1, so instead of normalizing every feature into mean 0 std 1, we normalize every row to mean 0 std 1...\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        xmean = x.mean(1, keepdim=True)# \n",
    "        xvar = x.var(1, keepdim=True) # \n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit var\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]        \n",
    "    \n",
    "torch.manual_seed(1337)\n",
    "module = BatchNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dim vectors\n",
    "x = module(x)\n",
    "x.shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, 0].mean(), x[:, 0].std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpathy_tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
